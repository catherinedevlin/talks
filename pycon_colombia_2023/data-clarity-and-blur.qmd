---
title: "Data: Clarity and Blur" 
subtitle: "PyCon Colombia 2023"
date: "2023-06-09"
author: "Catherine Devlin"
format: 
  revealjs:
    code-line-numbers: false
footer: "https://github.com/catherinedevlin/talks/"
logo: img/pycon-colombia.svg
---

![](img/pycon-colombia.svg)

https://github.com/catherinedevlin/talks/

::: {.notes}

Perdona que hable solo un poco de español. Si, quiere hablar conmigo en español después, por favor hable despacio y use gestos amplios.

:::

---

@catherinedevlin@tech.lgbt

Chelnik, the PostgreSQL elephant

![](img/chelnik.jpg){fig-alt="Small crocheted blue elephant" fig-align="center"}

::: {.notes}

No relation to Travis Oliphant 

:::


# [Quipu](https://essentials.neh.gov/projects/quipus-inca-language-knots) 

![](https://essentials.neh.gov/sites/default/files/quipu_v1.jpg){fig-alt="quipu" fig-align="center"}

::: {.notes}

Decimal system 

:::


## [Data comes first](https://www.bbc.com/news/business-39870485) 

![](https://ichef.bbci.co.uk/news/976/cpsprodpb/D5AA/production/_96089645_hi039302263.jpg.webp){fig-alt="cuneiform tablet" fig-align="center"}


::: {.notes}

Writing down stories, laws, prose... optional 

Recording data: mandatory 

::: 

## [type: int](https://www.nature.com/articles/d41586-021-01429-6)

![](img/bone.png){fig-alt="notched piece of bone" fig-align="center"}

::: {.notes}

Or not so advanced 

60,000 years ago, Neanderthal 

:::


## So where is it?

![](img/beginners-guide.png){fig-alt="Python Beginners' Guide" fig-align="center"}

::: {.notes}

:::

## Zen violation 

> There should be one-- and preferably only one --obvious way to do it.

::: {.notes}

There are lots of ways.  And frankly none of them is obvious.

On-your-own learning 

You may study, or stumble into, one technique 

:::

# Clarity and blur 

Clarity: about categories 

Blur: between categories

::: {.notes}

Clarity: what makes tecniques and approaches and technologies 
different 

Blur: Boundaries 

:::

# Relationships

+----------+---------+-------+
|  nombre  | diám_km | dia_d |
+----------+---------+-------+
| Mercurio |  4878   | 58.65 |
|  Venus   |  12100  | 243.0 |
|  Tierra  |  12756  |  1.0  |
|  Marte   |  6794   |  1.03 |
| Júpiter  | 142800  |  0.41 |
+----------+---------+-------+

Data from [Royal Museums Greenwich](https://www.rmg.co.uk/stories/topics/solar-system-data)

::: {.notes}

"Table" with "Rows"

"Relation" with "tuples"

Why?

:::

## Not data

Venus 

224.7 días

## Now it's data 

Venus **orbita alrededor del sol en** 224,7 días.

::: {.notes}

Meaning comes from relationship 

:::

## Table tells us the relationships

+----------+---------+-------+
|  nombre  | diám_km | dia_d |
+----------+---------+-------+
| Mercurio |  4878   | 58.65 |
|  Venus   |  12100  | 243.0 |
|  Tierra  |  12756  |  1.0  |
|  Marte   |  6794   |  1.03 |
| Júpiter  | 142800  |  0.41 |
+----------+---------+-------+


::: {.notes}

... between names of objects, quantities, etc.; 
the relationships make them into data.

:::

# Shapes of relationships

::: {.notes}

Is a rectangular table right?

No single answer

::: 

## Key:Value 

![](img/phonebook.jpg){fig-alt="phone book listings"}

::: {.notes}

Key: string, or at least hashable 

Value: simple or complex

:::

## Key-value access

```python
import dbm
with dbm.open('período_sideral_d.dbm', 'c') as db:
    db['Marte'] = str(686.98)

with dbm.open('período_sideral_d.dbm') as db:
    print(db['Marte'])
```

    b'686.98'

::: {.notes}

Implementations fast and simple 

Correspondence to dicts is great: "querying" is simply 
referring to a key

Stores byte strings - you could use JSON to serialize 
complex data into it, but you'd have to serialize and 
deserialize 
:::

## Shelve 

```python
import shelve
with shelve.open('planetas_shelf') as db:
    db['Marte'] = {'diám_km': 6794, 'año_d': 686.98}
    print(db['Marte']['diám_km'])
```

    6794

::: {.notes}

Shelve does that for you 

Values store python objects, incl composites 

Simplest document database - 

"document": 
case refers to the kind of structure that is 
represented 

Still query by key

:::

## Procedural "query"

[planetas.json](data/planetas.json)

```python
with shelve.open('planetas.shelve.db') as db:
    for planeta, planeta_info in db.items():
        for luna in planeta_info['lunas']:
            if (luna['diám_km'] or 0) > 2000:
                print (planeta, luna['nombre'], luna['diám_km'])
```

    [('Saturno', 'Titán', 5150.0),
    ('Tierra', 'Luna', 3476.0),
    ('Júpiter', 'Io', 3652.0),
    ('Júpiter', 'Europa', 3138.0),
    ('Júpiter', 'Ganímedes', 5262.0),
    ('Júpiter', 'Calisto', 4800.0),
    ('Neptuno', 'Tritón', 3500.0)]

::: {.notes}

Pull everything into memory, apply Python 

You don't have to learn anything 

bulky, slow 

:::

## JSONL: line-delimited JSON 

    {"nombre": "Venus", "masas_de_tierra": 0.82}
    {"nombre": "Tierra", "masas_de_tierra": 1.0, "lunas": ["Luna"]}
    {"nombre": "Marte", "y": 0.11, "lunas": ["Deimos", "Fobos"]}

::: {.notes}

No standard library support, but libraries like `jsonlines` and 
Pandas support it

:::

## Document query DSLs 

MongoDB query-by-example

```python
db.planetas.find({'diám_km': {'$gt': 10000},
                    'año_d': {'$lt': 500}}
```                      
Elastic query
![](img/elastic-query.png){fig-alt="Sample Elastic query"}

## jq 

```python
jq.compile('.[] | {nombre: .nombre, mes: [.lunas[]?.rev_d]}'
        ).input(sistema_solar).all()
```                      

    [{'nombre': 'Mercurio', 'mes': []},
    {'nombre': 'Venus', 'mes': []},
    {'nombre': 'Tierra', 'mes': [27.322]},
    {'nombre': 'Marte', 'mes': [0.319, 1.262]},
    {'nombre': 'Júpiter',
    'mes': [0.295, 0.298, 0.498, 0.675, ...

::: {.notes}

Independent DSL for navigating structures

like a JSON file, or a document 

Py libaries

::: 

## Rectangles

+----------+---------+-------+
|  nombre  | diám_km | dia_d |
+----------+---------+-------+
| Mercurio |  4878   | 58.65 |
|  Venus   |  12100  | 243.0 |
|  Tierra  |  12756  |  1.0  |
|  Marte   |  6794   |  1.03 |
| Júpiter  | 142800  |  0.41 |
+----------+---------+-------+

::: {.notes}

Intuitive and omnipresent.

Spreadsheets 

Clipboard with a sign-up form

:::
## Dataframes

```python
planetas.loc['Marte', 'año_d']
```

    686.98

```python
planetas[planetas.año_d > 1000] \
    [['máx_ua', 'diám_km', 'año_d']]
```

|         |   máx_ua |   diám_km |    año_d |
|:--------|---------:|----------:|---------:|
| Júpiter |     5.45 |    142800 |  4331.86 |
| Saturno |    10.07 |    120000 | 10760.3  |
| Urano   |    20.09 |     52400 | 30684.7  |
| Neptuno |    30.32 |     48400 | 60189.5  |

Pandas, Polars, agate, Dask, Ray, Modin, [more](https://github.com/jcmkk3/awesome-dataframes)

::: {.notes}

DataFrame object that supports LOTS of methods

Also repurposes square-bracket syntax for location and filtering

Familiar to Python folks

::: 

## Joins: why

+----------+--------+------+
|  nombre  | masa_t | luna |
+----------+--------+------+
| Mercurio |  0.06  | None |
|  Venus   |  0.82  | None |
|  Tierra  |  1.0   | Luna |
+----------+--------+------+


::: {.notes}

The problem with rectangular storage is that 
data often doesn't really fit that shape.

::: 

## uh-oh

+----------+--------+--------+--------+
|  nombre  | masa_t | luna_1 | luna_2 |
+----------+--------+--------+--------+
| Mercurio |  0.06  |  None  |  None  |
|  Venus   |  0.82  |  None  |  None  |
|  Tierra  |  1.0   |  Luna  |  Luna  |
|  Marte   |  0.11  | Deimos | Deimos |
+----------+--------+--------+--------+

## denormalized

+----------+--------+--------+
|  nombre  | masa_t |  luna  |
+----------+--------+--------+
| Mercurio |  0.06  |  None  |
|  Venus   |  0.82  |  None  |
|  Tierra  |  1.0   |  Luna  |
|  Marte   |  0.11  | Deimos |
|  Marte   |  0.11  | Fobos  |
+----------+--------+--------+

::: {.notes}

Use repetition to cover over mismatch 
between rectangles and shape 

Bulk 
Inconsistency danger 

Is it so bad?

:::

## Si, es tan mala

+----------+--------+-----------+
|  nombre  | masa_t |    luna   |
+----------+--------+-----------+
| Mercurio |  0.06  |    None   |
|  Venus   |  0.82  |    None   |
|  Tierra  |  1.0   |    Luna   |
|  Marte   |  0.11  |   Deimos  |
|  Marte   |  0.11  |   Fobos   |
| Júpiter  | 317.89 |  Adrastea |
| Júpiter  | 317.89 |  Amaltea  |
| Júpiter  | 317.89 |   Ananké  |
| Júpiter  | 317.89 |  Calisto  |
| Júpiter  | 317.89 |   Carmen  |
| Júpiter  | 317.89 |   Elara   |
| Júpiter  | 317.89 |   Europa  |
| Júpiter  | 317.89 | Ganímedes |
| Júpiter  | 317.89 |  Himalaya |
| Júpiter  | 317.89 |     Io    |
| Júpiter  | 317.89 |    Leda   |
| Júpiter  | 317.89 |  Lisitia  |
| Júpiter  | 317.89 |   Metis   |
| Júpiter  | 317.89 |  Pasifae  |
| Júpiter  | 317.89 |   Sinope  |
| Júpiter  | 317.89 |   Thebe   |
+----------+--------+-----------+

---

## Normalize 

+----------+--------+
|  nombre  | masa_t |
+----------+--------+
| Mercurio |  0.06  |
|  Venus   |  0.82  |
|  Tierra  |  1.0   |
|  Marte   |  0.11  |
+----------+--------+

+-----------+---------+
|   nombre  | planeta |
+-----------+---------+
|    Luna   |  Tierra |
|   Fobos   |  Marte  |
|   Deimos  |  Marte  |
+-----------+---------+

::: {.notes}

More elegant, but joining can be hard, too.

You've lost the business users.

:::


## Joining DataFrames

```python
lunas.join(planetas, 'planeta', lsuffix='_l', rsuffix='_p'
            )[['planeta', 'masas_t']]
```

|           | planeta   |   masas_t |
|:----------|:----------|----------:|
| Luna      | Tierra    |     1     |
| Fobos     | Marte     |     0.11  |
| Deimos    | Marte     |     0.11  |
| Metis     | Júpiter   |   317.89  |
| Adrastea  | Júpiter   |   317.89  |
| Amaltea   | Júpiter   |   317.89  |
| Thebe     | Júpiter   |   317.89  |

::: {.notes}

We still have repetition... it's just generated 
on-the-fly 

::: 

## SQL 

    SELECT p.nombre AS planeta,
        p.diám_km AS planeta_d_km,
        l.nombre AS luna,
        l.diámetro_media_km AS luna_d_km
    FROM   Planetas p
    JOIN   lunas l ON (l.planeta = p.nombre)
    WHERE  l.diámetro_media_km > 2000

+---------+--------------+-----------+-----------+
| planeta | planeta_d_km |    luna   | luna_d_km |
+---------+--------------+-----------+-----------+
|  Tierra |    12756     |    Luna   |   3476.0  |
| Júpiter |    142800    |     Io    |   3652.0  |
| Júpiter |    142800    |   Europa  |   3138.0  |
| Júpiter |    142800    | Ganímedes |   5262.0  |
| Júpiter |    142800    |  Calisto  |   4800.0  |
| Saturno |    120000    |   Titán   |   5150.0  |
| Neptuno |    48400     |   Tritón  |   3500.0  |
+---------+--------------+-----------+-----------+


::: {.notes}

SQL handles those joins mentioned before

::: 

## Documents too

```python
planetas['Tierra']['atmosfero'] = [{'molecule': 'N2', 'mw_amu': 28}, 
                                   {'molecule': 'O2', 'mw_amu': 32}, 
                                   {'molecule': 'CO2', 'mw_amu': 44}]
planetas['Marte']['atmosfero'] = [ 
                                   {'molecule': 'CO2', 'mw_amu': 44}]
```
::: {.notes}

Freeform - represent arbitrary data shape 

But tradeoff b/t repetition and joining remains 

Not such consensus of how to express joins in a document structure

::: 

## Raw SQL from Python 

- [DB-API2](https://cewing.github.io/training.codefellows/lectures/day21/intro_to_dbapi2.html)
- [Records](https://github.com/kennethreitz/records) by Kenneth Reitz

![](img/records.png){fig-alt="Records repo"}

## ORMs

Object-Relational Mappers

::: {.notes}

Famous... often assumed

:::

--- 

    engine = sa.create_engine('sqlite:///planetas.db')
    with sa.orm.Session(engine) as session:
        stmt = sa.select(Planeta).where(Planeta.diám_km < 50000)
        for planeta in session.execute(stmt).scalars():
            for luna in planeta.lunas:
                print(f'{luna.nombre} orbita a {planeta.nombre} '
                    f'en posición {luna.pos}')

    Luna orbita a Tierra en posición I
    Fobos orbita a Marte en posición I
    Deimos orbita a Marte en posición II
    Náyade orbita a Neptuno en posición III
    Thalassa orbita a Neptuno en posición IV
    Despina orbita a Neptuno en posición V
    Galatea orbita a Neptuno en posición VI
    Larisa orbita a Neptuno en posición VII
    Proteo orbita a Neptuno en posición VIII
    Tritón orbita a Neptuno en posición I
    Nereida orbita a Neptuno en posición II
    Caronte orbita a Plutón en posición I

::: {.notes}

You can work with instances through an ORM pretty much like they were 
any other Python objects.  Instead of having to think about the joins 
between related tables, you can navigate between related objects 
as attributes of the instances.

:::

## Boilerplate 

    from typing import List
    from typing import Optional
    from sqlalchemy import ForeignKey, create_engine
    from sqlalchemy import String, Float, Integer, String
    from sqlalchemy.orm import DeclarativeBase
    from sqlalchemy.orm import Mapped
    from sqlalchemy.orm import mapped_column
    from sqlalchemy.orm import relationship

    class Base(DeclarativeBase):
        pass

    class Planeta(Base):
        __tablename__ = "planetas"

        nombre: Mapped[str] = mapped_column(primary_key=True)
        mín_ua: Mapped[float] = mapped_column(Float)
        máx_ua: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
        mín_ua: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
        incl_orb_g: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
        diám_km: Mapped[int] = mapped_column(Integer)
        obl: Mapped[float] = mapped_column(Float)
        masas_t: Mapped[float] = mapped_column(Float)
        incl_g: Mapped[int] = mapped_column(Integer)
        año_d: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
        día_h: Mapped[float] = mapped_column(Float)
        
        lunas: Mapped[List["Luna"]] = relationship(
            back_populates="planeta"
        )

        def __str__(self):
            return self.nombre
            
    class Luna(Base):
        __tablename__ = "lunas"

        nombre: Mapped[str] = mapped_column(primary_key=True)
        pos: Mapped[str] = mapped_column(String)
        rev_d: Mapped[float] = mapped_column(Float)
        diám_km: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
        dist_km: Mapped[float] = mapped_column(Float)

        planeta_nombre: Mapped[str] = mapped_column(ForeignKey("planetas.nombre"))
        planeta: Mapped["Planeta"] = relationship(back_populates="lunas",)

::: {.notes}

One drawback is that you generally need to create a lot of code 
defining your tables in ORM terms before you can use an ORM.

Another is that all this syntax is ORM-dependent.  If you end up 
using another ORM in a different project, you'll have to learn a 
new syntax.

:::

## Define tables once 

- ORM first, then `Base.metadata.create_all(engine)`
- DDL first, then `metadata.reflect(bind=engine)` 

::: {.notes}

If you are strategic, and if the ORM you choose 
supports it, you can probably avoid defining the 
tables twice, once on the Python side and once on 
the SQL side.

:::

## More concise ORMs

[Hitchhiker's Guide](https://docs.python-guide.org/scenarios/db/)

![](img/guide-databases.png){fig-alt="Hitchhikers' Guide to Python Databases page")

## Query builders 

```python
planetas, lunas = pk.Tables('planetas', 'lunas')
q = (pk.Query 
    .select(lunas.star, planetas.diám_km)
    .from_(planetas) 
    .join(lunas) 
    .on(planetas.nombre == lunas.planeta_nombre)
    .where(planetas.diám_km < 60000)
    .where(lunas.diám_km > 100)
    )
print(q)
```

    SELECT "lunas".*,"planetas"."diám_km" FROM "planetas" JOIN "lunas" ON "planetas"."nombre"="lunas"."planeta_nombre" WHERE "planetas"."diám_km"<60000 AND "lunas"."diám_km">100

::: {.notes}

At the border between writing raw SQL and an ORM, consider a 
query builder.

SQL-based syntax (so, yes, another syntax to learn) - all the 
same concepts and keywords

Why, though?  Unless you just really hate SQL syntax?

:::

## Composable 

```python
    q = (pk.Query 
        .from_(planetas) 
        .where(planetas.diám_km < 60000)     
        .join(lunas) 
        .on(planetas.nombre == lunas.planeta_nombre)
        .select(lunas.star, planetas.diám_km, )
        .where(lunas.diám_km > 100)
        )
    print(q)
```

    SELECT "lunas".*,"planetas"."diám_km" FROM "planetas" JOIN "lunas" ON "planetas"."nombre"="lunas"."planeta_nombre" WHERE "planetas"."diám_km"<60000 AND "lunas"."diám_km">100

---

## PugSQL

![](img/pugsql.png){fig-alt="PugSQL webpage"}

::: {.notes}

Another ORM option

Define queries with SQL, each in its own .sql file, 
inport, invoke cleansly

:::


## Graph 

```{dot}
digraph P {
    "Mercurio" -> "Sol" [label = "orbita"]
    "Venus" -> "Sol" [label = "orbita"]
    "Tierra" -> "Sol" [label = "orbita"]
    "Luna" -> "Tierra" [label = "orbita"]
    "Marte" -> "Sol" [label = "orbita"]
    "Deimos" -> "Marte" [label = "orbita"]
    "Fobos" -> "Marte" [label = "orbita"]
}
```

::: {.notes}

Like a document, this can easily represent an arbitrary structure

Actually stored as node -> edge -> node

:::

## Graph 

```{dot}
digraph P {
    "Mercurio" -> "Sol" 
    "Venus" -> "Sol" 
    "Tierra" -> "Sol" 
    "Luna" -> "Tierra" 
    "Marte" -> "Sol" 
    "Deimos" -> "Marte" 
    "Fobos" -> "Marte" 
}
```
---

```{dot}
digraph P {
    layout=dot
    "Mercurio" -> "Sol" [label = "orbita"]
    "Venus" -> "Sol" [label = "orbita"]
    "Tierra" -> "Sol" [label = "orbita"]
    "Luna" -> "Tierra" [label = "orbita"]
    "Marte" -> "Sol" [label = "orbita"]
    "Deimos" -> "Marte" [label = "orbita"]
    "Fobos" -> "Marte" [label = "orbita"]
    "Venus" -> "CO2" [label = "tiene"]
    "Venus" -> "N2" [label = "tiene"]
    "Tierra" -> "CO2" [label = "tiene"]
    "Tierra" -> "N2" [label = "tiene"]
    "Tierra" -> "O2" [label = "tiene"]
    "Marte" -> "CO2" [label = "tiene"]
    "CO2" -> "O" [label = "contiene", lblstyle="above, sloped"]
    "CO2" -> "C" [label = "contiene", lblstyle="above, sloped"]
    "O2" -> "O" [label = "contiene", lblstyle="above, sloped"]
    "N2" -> "N" [label = "contiene", lblstyle="above, sloped"]
    "N2" -> "Taumeba" [label = "tóxica para"]
}
```

::: {.notes}

This looks out of hand, but you wouldn't necessarily 
view the whole graph at once.  That's what queries are for.

- Graph databases have query languages 
- Often inspired by SQL 
- Competing DSLs

:::

# Breaking boundaries 

- Data paradigm / shape 
- Query 
- Storage 

::: {.notes}

Three separate decisions 

"A SQL database"

:::

---

![](img/hstore.png){fig-alt="hstore docs" fig-align="center"}

---

## PostgreSQL JSON type

```sql
CREATE TABLE planetas (
    nombre TEXT PRIMARY KEY, info JSON);

select nombre, 
        doc->'diám_km' AS diám_km, 
        doc->'año_d' AS año_d
from planetas_docs
where (doc->>'diám_km')::int > 20000;

CREATE INDEX ON planetas_docs(((doc->>'diám_km')::int));
```

::: {.notes}

Like a doc database, JSON not just string

drill in to select 

index

:::

## Cross-paradigm hosting 

---

![](img/ferretdb.png){fig-alt="FerretDB webpage" fig-align="center"}

::: {.notes}

Supports MongoDB, but uses PostgreSQL for its storage engine

I lied in my earlier slide showing MongoDB; I was actually 
showing FerretDB.

:::

--- 

![](img/apache_age.png){fig-alt="Apache AGE webpage" fig-align="center"}

## Graphs without a graph database

[Using PostgreSQL as a graph database](https://tech.ingrid.com/sql-as-graph-database/)

```sql
WITH RECURSIVE traverse(node_id, entity_type, entity_id) AS (
    SELECT
    ...
)
SELECT
    traverse.entity_id as order_id
FROM traverse
...
```

::: {.notes}

RECURSIVE CTE: special sauce

PostgreSQL propaganda?

::: 

---

![](img/chelnik.jpg){fig-alt="small crocheted blue elephant" fig-align="center"}

::: {.notes}

Chelnik!

What did you do to our talk?

:::

# SQLite 

![](img/chelnik-blindfolded.png){fig-alt="small crocheted blue elephant, wearing blindfold" fig-align="center"}

::: {.notes}

:::

## Simplicity 

|              |one machine|distributed  |
|--------------|-----------|-------------|
|in memory     |SQLite     |Apache Ignite|
|single file   |SQLite     |rqlite       |
|server-managed|PostgreSQL |CockroachDB  |

- No server
- Python Standard Library support 

::: {.notes}

beloved for quick projects, demos, single-user apps

serverless: file format + libraries to access 

:::

## [SQLite for Application Files](https://www.sqlite.org/appfileformat.html)

![Document: SQLite As An Application File Format](img/sqlite-app-file.png){fig-alt="Article titled: SQL as an Application File Format" fig-align="center"}

::: {.notes}

In fact, it's so simple that you can use it when
you weren't even thinking about using a database at all - you were just looking for 
a data storage file format.  Because it's an efficient and versatile format. 
There's a good discussion of that in the SQLite docs.

:::


## Simple != Weak 

```{dot}
digraph P {
    layout=dot
    "Data source" -> "SQLite"
    "SQLite" -> "reader 1"
    "SQLite" -> "reader 2"
    "SQLite" -> "reader 3"
    "SQLite" -> "reader 4"
    "SQLite" -> "reader 5"
}
```

::: {.notes}

Python "scripting" language?

large amounts OK 

lots of users / processes OK

Publish data, updated occasionally

lots of writers: not OK 

:::

## Baked data 

Simon Willison: [The Baked Data architectural pattern](https://simonwillison.net/2021/Jul/28/baked-data/)

![](img/baked-data.png){fig-alt="Baked Data article" fig-align="center"}

::: {.notes}

Simon Willison wrote this great article on cheaply and easily hosting an 
application if it relies on infrequently-updated data.  Just put that data 
in a single-file database like SQLite, and a cheap and basic real or virtual 
server can handle the dynamic part.

::: 

## Datasette 

![](img/datasette-map.png){fig-alt="Datasette page with map" fig-align="center"}

::: {.notes}

Mentioning Simon Willison is my excuse to plug his amazing project Datasette, 
a versatile expandable tool for exploring and visualizing SQLite databases.  

As you might expect for SQLite, the server is really easy to install and run.  
It can even point to a SQLite file that's publicly hosted rather than on your 
own machine.  In fact...

:::

## Datasette-lite 

[https://lite.datasette.io/?url=https://github.com
    /catherinedevlin/talks/blob/master
    /pycon_colombia_2023/data/planetas.sqlite](https://lite.datasette.io/?url=https://github.com/catherinedevlin/talks/blob/master/pycon_colombia_2023/data/planetas.sqlite)


::: {.notes}

blurring boundaries: PyIodide

Simon Willison did this with Datasette!

Why would I put this long ugly URL on my slide?

Only code!

I have never been this lazy in my life, and I love it!

:::

## Cross-paradigm SQLite

- [SQLite as a document database](https://dgl.cx/2020/06/sqlite-json-support)
- [simple-graph](https://github.com/dpapathanasiou/simple-graph)
- [FTS5](https://www.sqlite.org/fts5.html): full-text for search

## Federation 

::: {.notes}

Open your eyes now, chelnik 

Blur boundaries:

Leave data in place... query it anyway 

:::

## PostgreSQL Foreign Data Wrappers

![](img/mongo_fdw.png){fig-alt="Screenshot of using mongo_fdw" fig-align="center"}

[source: CrunchyData blog](https://www.crunchydata.com/blog/easy-mongo-from-your-postgres)

::: {.notes}

At that point, you can run queries against your foreign tables 
and pretty much forget that they are foreign tables!

:::

## Cloud storage / big data 

![](img/parquet_fdw.png){fig-alt="Parquet Foreign Data Wrapper repo page" fig-align="center"}

::: {.notes}

Often, gangs of bullies accost innocent programmers 
and tell them that they have to use a big data file 
format like Parquet.

:::

## [Many many wrappers...](https://wiki.postgresql.org/wiki/Foreign_data_wrappers)

::: {.notes}

Ease, quality, documentation

performance, read-only 

:::

## Boo SQL 

- [annoying syntax](https://github.com/catherinedevlin/rogue-sql)
- [mathematically poor](https://www.scattered-thoughts.net/writing/against-sql)
- not composeable 

::: {.notes}

Why is SQL so popular?  24 years of seeing its end predicted

:::

## Hooray SQL 

- Super-mature
- Expressive
- Readable 
- Universal(ish)

SQL ecosystem growing

::: {.notes}

New technologies are at least as likely to support SQL 
as old ones are 

and (uses of) SQLite are *still growing!  For example...

:::

## SQL to Pandas 

```python
qry = """SELECT p.nombre, p.diám_km, 
        l.nombre AS luna,
        l.diám_km AS luna_diám_km
FROM   planetas p 
JOIN   lunas l ON (l.planeta_nombre = p.nombre)"""
df = pd.read_sql(qry, 'sqlite:///planetas.db')
...
df.write_sql("new_tbl", connection)
```

## [JupySQL](https://jupysql.ploomber.io/en/latest/quick-start.html)

![](img/jupysql){fig-alt="JupySQL webpage" fig-align="center"}

::: {.notes}

I love JupySQL because it's the second time somebody picked up 
one of my personal projects and made it into something far 
better than I could.

::: 

## JupySQL to Pandas

    %%sql result << 
    SELECT p.nombre, p.diám_km, 
            l.nombre AS luna,
            l.diám_km AS luna_diám_km
    FROM   planetas p 
    JOIN   lunas l ON (l.planeta_nombre = p.nombre)

    result.DataFrame()

::: {.notes}

## [dbcli](https://www.dbcli.com/)

![](img/dbcli.png){fig-alt="DBCLI homepage"}

::: {.notes}

Relational command-line query tool 

Python-based, powerful user-driven

Ancient past as one of my personal projects 

::: 

## SQL for Big Data 

- File formats like Parquet, Avro, ORC
- Engines for access: Apache Spark, Presto, DuckDB, Apache Drill...

::: {.notes}

"Big Data" and "NoSQL" are often used as near-synonyms, yet most of the 
"Big Data" query engines support SQL.  They may also support a variety 
of APIs for Python-style access, but of course, those APIs are different
for each one.

:::

## dbt: SQL for ETL 

![](img/dbt.png){fig-alt="dbt webpage" fig-align="center"}

::: {.notes}

Data transformation 

Very old-fashioned SQL

-ize words: Organize, parallelize, visualize

Clean and manageable

:::

## Family members

SQLite -> rqlite, DuckDB 

PostgreSQL -> CockroachDB, Crunchy, Yugabyte, Supabase...

::: {.notes}

Plus the proprietary hosted variants.  

Leveraging personal & community experience 

::: 

# Order vs. Freedom 

---

![](img/csv.png){fig-alt="CSV of planet info" fig-align="center"}


::: {.notes}

Generally, in these rectangle-based formats, it's very 
clear which fields are and are not present.

:::

--- 

```sql
ALTER TABLE planetas 
ADD COLUMN (anillos BOOL 
                    NOT NULL 
                    DEFAULT FALSE);
 ```


::: {.notes}

In fact, you may need to run code to add a field 
that wasn't previously present.

:::

---

```python
planetas['Saturno']['anillos'] = True
```

::: {.notes}

Whereas, in documents or graphs, by default you can 
just toss in whatever values and relationships you 
wish.  

This can be very freeing and fun.

:::

---

    planetas['Júpiter']['anillos'] = True
    planetas['Tierra']['anllos'] = False

::: {.notes}

Mistakes 

Not self-documented - 
your eyes or other tools 

:::

--- 

![](img/type-hints.png){fig-alt="Python docs page on type hints" fig-align="center"}

::: {.notes}

Does this tradeoff remind you of anything?

::: 

## Dataclasses / attrs

```python
from dataclasses import dataclass 

@dataclass 
class Planeta:

    nombre: str 
    diám_km: int
    año_d: float

Planeta(nombre='Júpiter', diám_km=142800, año_d=4331.865)
```

::: {.notes}

As Lukasz mentioned this morning, type hints make possible 
great tools like dataclasses or attrs, or Pydantic for 
validation

:::

--- 
```python
@dataclass 
class Planeta_Dataclass:
    nombre: str 
    diám_km: int
    año_d: float

class Planeta_Model(Base):
    __tablename__ = "planetas"

    nombre: Mapped[str] = mapped_column(primary_key=True)
    diám_km: Mapped[int] = mapped_column(Integer)
    año_d: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
```

::: {.notes}

So close together!  Do we really need to define them
separately!

:::

## SQLAlchemy - dataclass (attrs, Pydantic)

```python
from sqlalchemy.orm import MappedAsDataclass

class Planeta(MappedAsDataclass, Base):
    __tablename__ = "planetas"

    nombre: Mapped[str] = mapped_column(primary_key=True)
    ...

```

::: {.notes}

Latest SQLAlchemy release blurs that boundary 
with a mixin

Also integrations with attrs and Pydantic

::: 

# [JSON Schema](https://json-schema.org/)

```json
{
"$schema": "https://json-schema.org/draft/2020-12/schema",
"$id": "https://example.com/product.schema.json",
"title": "Product",
"description": "A product from Acme's catalog",
"type": "object",
"properties": {
    "productId": {
    "description": "The unique identifier for a product",
    "type": "integer"
    }
},
"required": [ "productId" ]
}
```

::: {.notes}

JSON Schema is like optional type hints, but for 
a document structure that doesn't normally enforce 
a schema

Generate random data, Swagger docs 

:::

## datamodel-codegen

```bash
datamodel-codegen --input planetas.csv --input-file-type csv --output-model-type dataclasses.dataclass
```

    # generated by datamodel-codegen:
    #   filename:  planetas.csv
    #   timestamp: 2023-06-05T01:41:29+00:00

    from __future__ import annotations

    from dataclasses import dataclass

    @dataclass
    class Model:
        nombre: str
        mín_ua: str
        máx_ua: str
        incl_orb_g: str
        diám_km: str
        obl: str
        masas_t: str
        incl_g: str
        año_d: str
        día_h: str

::: {.notes}

Laziness!

Lots of ways to describe data.

Automated converters!  Search for them!

:::

## Automated converters

```{dot}
digraph {
    subgraph python { 
        style=filled;
        color=lightblue;
        dataclass 
        attrs
        pydantic
    }
    dataclass -> DDL [label="simple-ddl-generator"]
    pydantic -> DDL [label="simple-ddl-generator"]
    attrs
    DDL -> DDL [label="simple-ddl-generator"]
    JSON -> JSONSchema [label=genson]
    JSONSchema -> dataclass [label=statham, dir=both]
    ORM -> DDL [label="simple-ddl-generator"]
    ORM -> dataclass [label=SQLAlchemy, dir=both URL="https://docs.sqlalchemy.org/en/20/orm/dataclasses.html"]
    DDL -> dataclass [label=omymodels]
    DDL -> ORM [label=omymodels]
    attrs -> ORM [lable=SQLAlchemy dir=both]
    JSONSchema -> dataclass [label="datamodel-code-generator"]
    dict -> dataclass [label="datamodel-code-generator"]
    JSON -> dataclass [label="datamodel-code-generator"]
    pydantic -> JSONSchema [label=".schema_json"]
    JSONSchema -> webform [label="react-jsonschema-webform" URL="https://rjsf-team.github.io/react-jsonschema-form/docs/"]
    JSONSchema -> webform [label="JSONForms.io" URL="https://jsonforms.io/"]
    JSONSchema -> DDL [label="jsonschema2db" URL="https://github.com/better/jsonschema2db"]
    JSONSchema -> DDL [label="jsonschema2sql" URL="https://github.com/hashhar/jsonschema2sql"]
}
```

::: {.notes}

Partial map - my own research 

pandat?

:::

# Clarity please 

## Units 

![](img/mars-probe-collision.png){fig-alt="News story on loss of Mars probe" fig-align="center"}

[Pint](https://pint.readthedocs.io/en/stable/) 

::: {.notes}

Suffixes in field names 

:::

## SQL comments 

    COMMENT ON COLUMN planetas.día_h IS 'período de rotación, en horas'

![](img/with_comment.png){fig-alt="Table description with column comment" fig-align="center"}

# Quipu redux 

![](https://essentials.neh.gov/sites/default/files/quipu_v1.jpg){fig-alt="quipu" fig-align="center"}

::: {.notes}

Can interpret numbers 

Cannot interpret anchor knots colors - metadata 

Alien invasion - protect and preserve 

:::

# Open Khipu

![](img/open-khipu.png){fig-alt="Open Khipu repo" fig-align="center"}

::: {.notes}

But let's end on a happy note!  There's a large open-data 
database of data meticulously describing thousands of quipu 
that have survived.  

::: 


## Datasett-Lite for quipu 

https://lite.datasette.io/?url=https://github.com/khipulab/open-khipu-repository/blob/master/khipu.db


::: {.notes}

And, because it's a SQLite database posted to the web, 
you guessed it, we can use Datasette-Lite to browse it, 
right where it is, writing no code.

Published in SQLite, browsable with datasette

Modern data technology - to ancient one 

Maybe even help researchers restore lost metadata 

:::
